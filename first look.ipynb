{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import yaml\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler\n",
    "from tweepy.api import API as Twitter\n",
    "from tweepy.error import TweepError\n",
    "from tweepy.parsers import JSONParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7f6b2e676f90>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f6b2e39fb40>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f6b2e39fbb0>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('twitter_api_creds.json', \"rb\") as f:\n",
    "    conf = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'twitter': {'api': {'pause': 1,\n",
       "   'app': {'key': 'X9JqOAFJ8GjYNqvEolEpvZdE2',\n",
       "    'secret': '4j5TdZC2o5YfSFnlASa10x9KLE3FN4P5FTOwHLSrx8FYYem7c1',\n",
       "    'token': '2620986611-pOP0uh0cEkgh8yxmJdNEpK3kD4DIKTSJvmKJxR6',\n",
       "    'token_secret': 'yslRiqrk6EriZxFmeWAkJItWOD9PtdVOLe3h5IaoskRVY'}}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(conf[\"twitter\"][\"api\"][\"app\"][\"key\"], conf[\"twitter\"][\"api\"][\"app\"][\"secret\"])\n",
    "auth.set_access_token(conf[\"twitter\"][\"api\"][\"app\"][\"token\"], conf[\"twitter\"][\"api\"][\"app\"][\"token_secret\"])\n",
    "twitter = Twitter(auth, parser=JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = twitter.search('#GoT', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['statuses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http_regexp = 'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'\n",
    "http_regexp = 'https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://t.co/YbBI6vkzYh', 'https://t.co/j6XbRWYPqN']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(http_regexp,'I miss the old Tyrion #GoT #GameofThrones https://t.co/YbBI6vkzYh https://t.co/j6XbRWYPqN' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(http_regexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I miss the old Tyrion #GoT #GameofThrones  '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.sub('','I miss the old Tyrion #GoT #GameofThrones https://t.co/YbBI6vkzYh https://t.co/j6XbRWYPqN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    \n",
    "    return pattern.sub('',text)\n",
    "\n",
    "def remove_hashes(text):\n",
    "    \n",
    "    return text.replace('#','')\n",
    "\n",
    "def remove_newline(text):\n",
    "    return text.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "    out_list=[]\n",
    "\n",
    "    for tweet in tweets['statuses']:\n",
    "        text= tweet['text']\n",
    "        url_clean = remove_urls(text)\n",
    "        hash_clean = remove_hashes(url_clean)\n",
    "        newline_clean = remove_newline(hash_clean)\n",
    "        out_list.append(newline_clean)\n",
    "        \n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_texts = clean_tweets(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @chriskane0: @BuzzFeed Wonder what @HBO didnâ€™t like in the Pilot episode. Was it the backlash of the Game Of Thrones final season  gotpâ€¦',\n",
       " 'RT @afterbuzztv: HBO has cancelled plans for a GameOfThrones prequel starring NaomiWatts. The network shot a pilot episode in Northern Irâ€¦',\n",
       " \"RT @notamoviepod: GoT update â„ï¸ ðŸ”¥   â€¢ Age of Heroes prequel canceled due to lengthy post-production &amp; 'issues during filming'  â€¢ Targaryenâ€¦\",\n",
       " \"RT @notamoviepod: GoT update â„ï¸ ðŸ”¥   â€¢ Age of Heroes prequel canceled due to lengthy post-production &amp; 'issues during filming'  â€¢ Targaryenâ€¦\",\n",
       " 'StarWars and GOT prequel BOTH canceled suddenly?   What did Benioff or Weiss do? ',\n",
       " \"RT @notamoviepod: GoT update â„ï¸ ðŸ”¥   â€¢ Age of Heroes prequel canceled due to lengthy post-production &amp; 'issues during filming'  â€¢ Targaryenâ€¦\",\n",
       " 'Ppl hatin on D&amp;D, Pretty sure they will b ok, didnt they sign a 9 figure deal with netflix? if dont like them dontâ€¦ ',\n",
       " 'People are fickle and @HBO needs to get something in production before GOT fans move on to something else, which tâ€¦ ',\n",
       " 'Naomi Watts should be as successful as Nicole Kidman but people seem to just have it out for her all the time.â€¦ ',\n",
       " \"RT @notamoviepod: GoT update â„ï¸ ðŸ”¥   â€¢ Age of Heroes prequel canceled due to lengthy post-production &amp; 'issues during filming'  â€¢ Targaryenâ€¦\",\n",
       " 'RT @freefolkbot: The Lannisters send their regards GoT GameofThrones  ',\n",
       " 'RT @RedditFreeFolk: HBO wanted 10 seasons and they did 8 just because of Star Wars @ r/FreeFolk &gt;  GameofThrones Gâ€¦',\n",
       " 'The Lannisters send their regards GoT GameofThrones  ',\n",
       " \"RT @notamoviepod: GoT update â„ï¸ ðŸ”¥   â€¢ Age of Heroes prequel canceled due to lengthy post-production &amp; 'issues during filming'  â€¢ Targaryenâ€¦\",\n",
       " 'And it seems that neither one of them are going to get awards nominations for their portrayals of Gretchen Carlson.â€¦ ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'RT @chriskane0: @BuzzFeed Wonder what @HBO didnâ€™t like in the Pilot episode. Was it the backlash of the Game Of Thrones final season  gotpâ€¦', 'entities': (@HBO, the Game Of Thrones)}\n",
      "{'sentence': 'RT @afterbuzztv: HBO has cancelled plans for a GameOfThrones prequel starring NaomiWatts. The network shot a pilot episode in Northern Irâ€¦', 'entities': (HBO, NaomiWatts, Northern Ir)}\n",
      "{'sentence': \"RT @notamoviepod: GoT update â„ï¸ ðŸ”¥   â€¢ Age of Heroes prequel canceled due to lengthy post-production &amp; 'issues during filming'  â€¢ Targaryenâ€¦\", 'entities': (Targaryen,)}\n",
      "{'sentence': \"RT @notamoviepod: GoT update â„ï¸ ðŸ”¥   â€¢ Age of Heroes prequel canceled due to lengthy post-production &amp; 'issues during filming'  â€¢ Targaryenâ€¦\", 'entities': (Targaryen,)}\n",
      "{'sentence': 'StarWars and GOT prequel BOTH canceled suddenly?   What did Benioff or Weiss do? ', 'entities': (StarWars, GOT, Benioff, Weiss)}\n",
      "{'sentence': \"RT @notamoviepod: GoT update â„ï¸ ðŸ”¥   â€¢ Age of Heroes prequel canceled due to lengthy post-production &amp; 'issues during filming'  â€¢ Targaryenâ€¦\", 'entities': (Targaryen,)}\n",
      "{'sentence': 'Ppl hatin on D&amp;D, Pretty sure they will b ok, didnt they sign a 9 figure deal with netflix? if dont like them dontâ€¦ ', 'entities': (9,)}\n",
      "{'sentence': 'People are fickle and @HBO needs to get something in production before GOT fans move on to something else, which tâ€¦ ', 'entities': (@HBO,)}\n",
      "{'sentence': 'Naomi Watts should be as successful as Nicole Kidman but people seem to just have it out for her all the time.â€¦ ', 'entities': (Naomi Watts, Nicole Kidman)}\n",
      "{'sentence': \"RT @notamoviepod: GoT update â„ï¸ ðŸ”¥   â€¢ Age of Heroes prequel canceled due to lengthy post-production &amp; 'issues during filming'  â€¢ Targaryenâ€¦\", 'entities': (Targaryen,)}\n",
      "{'sentence': 'RT @freefolkbot: The Lannisters send their regards GoT GameofThrones  ', 'entities': (Lannisters, GameofThrones)}\n",
      "{'sentence': 'RT @RedditFreeFolk: HBO wanted 10 seasons and they did 8 just because of Star Wars @ r/FreeFolk &gt;  GameofThrones Gâ€¦', 'entities': (HBO, 10, 8)}\n",
      "{'sentence': 'The Lannisters send their regards GoT GameofThrones  ', 'entities': (Lannisters, GameofThrones)}\n",
      "{'sentence': \"RT @notamoviepod: GoT update â„ï¸ ðŸ”¥   â€¢ Age of Heroes prequel canceled due to lengthy post-production &amp; 'issues during filming'  â€¢ Targaryenâ€¦\", 'entities': (Targaryen,)}\n",
      "{'sentence': 'And it seems that neither one of them are going to get awards nominations for their portrayals of Gretchen Carlson.â€¦ ', 'entities': (one, Gretchen Carlson)}\n"
     ]
    }
   ],
   "source": [
    "for sentence in cleaned_texts:\n",
    "    doc = nlp(sentence)\n",
    "    entities = doc.ents\n",
    "    if len(entities) > 0:\n",
    "        output = dict(\n",
    "            sentence=sentence,\n",
    "            entities=entities\n",
    "        )\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import load_data, text_classifier_learner, AWD_LSTM\n",
    "import torch\n",
    "from pathlib import Path, PosixPath, PurePosixPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2070 SUPER'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PurePosixPath('model/sentiment')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=PurePosixPath('./model/sentiment')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PurePosixPath('model/sentiment/data_clas.pkl')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path/'data_clas.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "cannot instantiate 'PosixPath' on your system",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-1b182c1c12b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#path=Path('c:/Users/jjc/Projects/pydata2019/pydata2019-nlp-system/step3_nlp/model/sentiment/')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_clas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data_clas.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlearn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_classifier_learner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_clas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAWD_LSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\fastai\\basic_data.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(path, file, bs, val_bs, num_workers, dl_tfms, device, collate_fn, no_check, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;34m\"Load a saved `DataBunch` from `path/file`. `file` can be file-like (file or buffer)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_pathlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m     \u001b[0mll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m     return ll.databunch(path=path, bs=bs, val_bs=val_bs, num_workers=num_workers, dl_tfms=dl_tfms, device=device,\n\u001b[0;32m    279\u001b[0m                         collate_fn=collate_fn, no_check=no_check, **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\pathlib.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             raise NotImplementedError(\"cannot instantiate %r on your system\"\n\u001b[1;32m-> 1006\u001b[1;33m                                       % (cls.__name__,))\n\u001b[0m\u001b[0;32m   1007\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: cannot instantiate 'PosixPath' on your system"
     ]
    }
   ],
   "source": [
    "bs=48\n",
    "#path=Path('c:/Users/jjc/Projects/pydata2019/pydata2019-nlp-system/step3_nlp/model/sentiment/')\n",
    "data_clas = load_data(path, 'data_clas.pkl', bs=bs)\n",
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
